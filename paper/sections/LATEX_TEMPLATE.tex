# LaTeX Template for Conference Paper

```latex
\documentclass[conference]{IEEEtran}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{cite}

\title{Transfer Learning for Low-Resource Speaker Verification in Regional Indian Languages}

\author{
\IEEEauthorblockN{[Author Names]}
\IEEEauthorblockA{[Institution]\\
[Email]}
}

\begin{document}

\maketitle

\begin{abstract}
Speaker verification systems typically require substantial amounts of training data per speaker, which is often unavailable for low-resource regional languages like Hindi and Kannada. This study investigates transfer learning from English speaker embeddings to Hindi/Kannada speakers with only 3 training utterances per speaker. We fine-tuned a pretrained ECAPA-TDNN model on 351 speakers using 8 kHz telephone audio, achieving 24.90\% Equal Error Rate (EER) with 75.10\% accuracy. Validation performance showed 6.54\% EER, indicating an overfitting gap of 18.36 percentage points due to limited training data. Our results demonstrate that transfer learning is feasible but requires careful encoder adaptation and increased training data (10-20 utterances) for production deployment.
\end{abstract}

\begin{IEEEkeywords}
Speaker verification, ECAPA-TDNN, transfer learning, low-resource languages, Hindi, Kannada
\end{IEEEkeywords}

\section{Introduction}

Speaker verification determines whether two speech samples originate from the same person. While modern deep learning systems achieve excellent performance on high-resource languages like English, deploying these systems for regional Indian languages presents challenges: data scarcity, telephone-quality audio (8 kHz), and linguistic diversity.

\subsection{Research Questions}
This work addresses:
\begin{enumerate}
    \item Can pretrained English models transfer to Hindi/Kannada?
    \item What performance is achievable with 3 training files per speaker?
    \item What are practical limitations and improvements?
\end{enumerate}

\section{Related Work}

\subsection{Speaker Verification}
Traditional approaches (i-vectors, PLDA) have been superseded by deep learning methods: x-vectors \cite{snyder2018}, ECAPA-TDNN \cite{desplanques2020}, and transformer-based embeddings \cite{koluguri2022}.

\subsection{Transfer Learning}
VoxCeleb \cite{nagrani2017} provides English pretraining standard. Limited work exists on extreme low-resource scenarios (3 files/speaker) for Indian languages.

\section{Methodology}

\subsection{Dataset}
\begin{itemize}
    \item \textbf{Speakers}: 351 (Hindi and Kannada)
    \item \textbf{Training}: 1,053 files (3 per speaker)
    \item \textbf{Test}: 16,277 files ($\sim$46 per speaker)
    \item \textbf{Quality}: 8 kHz telephone audio
\end{itemize}

\subsection{Model Architecture}
We use ECAPA-TDNN \cite{desplanques2020} pretrained on VoxCeleb2:
\begin{enumerate}
    \item 80-dimensional log-Mel filterbanks
    \item Time-delay neural network with squeeze-excitation blocks
    \item Statistics pooling (mean + std)
    \item 192-dimensional embeddings
    \item AAM-Softmax classifier (margin=0.2, scale=30)
\end{enumerate}

\subsection{Training}
\begin{itemize}
    \item \textbf{Optimizer}: Adam (lr=0.00005, weight decay=0.0001)
    \item \textbf{Scheduler}: ReduceLROnPlateau
    \item \textbf{Batch size}: 32
    \item \textbf{Epochs}: 30 (no encoder freezing)
\end{itemize}

\subsection{Evaluation}
10,000 balanced verification trials (5,000 positive, 5,000 negative) using cosine similarity scoring. Metrics: EER, accuracy, minDCF.

\section{Results}

\subsection{Performance Metrics}
Table \ref{tab:results} shows final test performance.

\begin{table}[h]
\centering
\caption{Test Set Performance (Best Model - Epoch 18)}
\label{tab:results}
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Equal Error Rate (EER) & 24.90\% \\
Accuracy at EER & 75.10\% \\
EER Threshold & 0.1112 \\
Minimum DCF & 0.9490 \\
False Acceptance Rate & 24.90\% \\
False Rejection Rate & 24.90\% \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Training Dynamics}
Best validation EER of 6.54\% achieved at epoch 18. Final test EER of 24.90\% indicates 18.36 percentage point overfitting gap due to limited training data.

\subsection{Score Distribution}
Figure \ref{fig:scores} shows clear separation between genuine ($\mu=0.25$, $\sigma=0.15$) and impostor ($\mu=-0.05$, $\sigma=0.12$) scores with moderate overlap.

\begin{figure}[h]
\centering
\includegraphics[width=0.45\textwidth]{figures/ecapa_score_distribution.png}
\caption{Score distribution for genuine vs impostor pairs}
\label{fig:scores}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.45\textwidth]{figures/ecapa_roc_curve.png}
\caption{ROC curve showing TPR vs FPR}
\label{fig:roc}
\end{figure}

\section{Discussion}

\subsection{Transfer Learning Success}
Pretrained English model successfully adapted to Hindi/Kannada. Encoder required full unfreezing—freezing caused 49.94\% EER failure. Final 24.90\% EER significantly outperforms random guessing (50\%).

\subsection{Low-Resource Challenge}
Three files per speaker proved insufficient for robust generalization. The 18.36 pp overfitting gap indicates model memorization. Performance is within expected range for this data constraint (20-30\% EER).

\subsection{Comparison with Baselines}
\begin{itemize}
    \item \textbf{Random guessing}: $\sim$50\% EER
    \item \textbf{Traditional i-vectors (low-resource)}: 30-40\% EER
    \item \textbf{Our ECAPA-TDNN}: 24.90\% EER
    \item \textbf{Well-resourced ECAPA-TDNN}: 5-10\% EER
\end{itemize}

\section{Conclusions}

This study demonstrates viable transfer learning from English to Hindi/Kannada speakers but reveals critical data limitations. With 3 training utterances per speaker, we achieved 24.90\% EER—reasonable for the constraint but insufficient for production. Key findings:

\begin{enumerate}
    \item Encoder adaptation is essential (freezing fails)
    \item Data quantity matters (18.36 pp overfitting with 3 files)
    \item Transfer learning works (75.10\% vs 50\% random)
\end{enumerate}

\textbf{Future work}: Increase training data to 10-20 files/speaker, implement PLDA backend, train TiTANet for comparison, explore data augmentation.

\section*{Acknowledgments}
[If applicable]

\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}
```

## BibTeX References

```bibtex
@inproceedings{desplanques2020,
  title={ECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation in TDNN Based Speaker Verification},
  author={Desplanques, Brecht and Thienpondt, Jenthe and Demuynck, Kris},
  booktitle={Proc. Interspeech},
  year={2020}
}

@inproceedings{snyder2018,
  title={X-vectors: Robust DNN Embeddings for Speaker Recognition},
  author={Snyder, David and Garcia-Romero, Daniel and Sell, Gregory and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={Proc. ICASSP},
  year={2018}
}

@inproceedings{nagrani2017,
  title={VoxCeleb: A Large-Scale Speaker Identification Dataset},
  author={Nagrani, Arsha and Chung, Joon Son and Zisserman, Andrew},
  booktitle={Proc. Interspeech},
  year={2017}
}

@inproceedings{koluguri2022,
  title={TitaNet: Neural Model for Speaker Representation with 1D Depth-wise Separable Convolutions and Global Context},
  author={Koluguri, Nithin Rao and Park, Taejin and Ginsburg, Boris},
  booktitle={Proc. ICASSP},
  year={2022}
}

@article{dehak2011,
  title={Front-End Factor Analysis for Speaker Verification},
  author={Dehak, Najim and Kenny, Patrick J and Dehak, R{\'e}da and Dumouchel, Pierre and Ouellet, Pierre},
  journal={IEEE Transactions on Audio, Speech, and Language Processing},
  volume={19},
  number={4},
  pages={788--798},
  year={2011}
}

@inproceedings{ko2015,
  title={Audio Augmentation for Speech Recognition},
  author={Ko, Tom and Peddinti, Vijayaditya and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={Proc. Interspeech},
  year={2015}
}
```
